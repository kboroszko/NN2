{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"hello\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "\n",
    "x = np.load('data/gsn_img_uint8.npy')\n",
    "y = np.load('data/gsn_msk_uint8.npy')\n",
    "\n",
    "x_test = np.load('data/test_gsn_image.npy')\n",
    "y_test = np.load('data/test_gsn_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax.imshow(img,aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "def imshow_many(imgs):\n",
    "    n = imgs.shape[0]\n",
    "    if n < 20 :\n",
    "        cols = 5\n",
    "        rows = int((n+4)/5)\n",
    "        fig = plt.figure(figsize=(cols * 4, rows * 4))\n",
    "    else :\n",
    "        cols = 10\n",
    "        rows = int((n+9)/10)\n",
    "        fig = plt.figure(figsize=(cols * 2, rows * 2))\n",
    "    \n",
    "    for i in range(n):\n",
    "        sub = fig.add_subplot(rows, cols, i + 1)\n",
    "        if(imgs.shape[3] == 1) :\n",
    "            imgs = imgs.reshape((imgs.shape[0], imgs.shape[1], imgs.shape[2]))\n",
    "        sub.imshow(imgs[i], interpolation='nearest')\n",
    "\n",
    "def imshow_masked(samples):\n",
    "    n = len(samples)\n",
    "    if n < 20 :\n",
    "        cols = 5\n",
    "        rows = int((n+4)/5)\n",
    "        fig = plt.figure(figsize=(cols * 4, rows * 4))\n",
    "    else :\n",
    "        cols = 10\n",
    "        rows = int((n+9)/10)\n",
    "        fig = plt.figure(figsize=(cols * 2, rows * 2))\n",
    "    \n",
    "    for i in range(n):\n",
    "        sub = fig.add_subplot(rows, cols, i + 1)\n",
    "        image = samples[i]['image']\n",
    "        mask = samples[i]['mask']\n",
    "        if torch.is_tensor(image) :\n",
    "            image = image.permute(1,2,0)\n",
    "        if torch.is_tensor(mask) :\n",
    "            mask = mask.permute(1,2,0)\n",
    "        mask = mask.reshape((mask.shape[0], mask.shape[1]))\n",
    "        sub.imshow(image, interpolation='nearest')\n",
    "        sub.imshow(mask, interpolation='nearest', cmap='jet', alpha=0.6)\n",
    "    \n",
    "start = 0\n",
    "end = 5\n",
    "samples = [{'image' : a, 'mask' : b} for a,b in zip(x[start:end], y[start:end])]\n",
    "imshow_masked(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        resized_mask = transform.resize(mask, (new_h, new_w))\n",
    "        mask = (resized_mask > 0.5).astype(resized_mask.dtype)\n",
    "\n",
    "        return {'image': img, 'mask': mask}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        mask = mask[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        return {'image': image, 'mask': mask}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        mask = mask.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'mask': torch.from_numpy(mask)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    \"\"\"Images and masks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, gsn_img, gsn_mask, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gsn_img (np.array): numpy array of images\n",
    "            gsn_mask (np.array): numpy array of masks\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.images = gsn_img\n",
    "        self.masks = gsn_mask\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "\n",
    "        sample = {'image': image, 'mask': mask}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = Rescale(256)\n",
    "crop = RandomCrop(127)\n",
    "composed = transforms.Compose([Rescale(150),\n",
    "                               RandomCrop(128),\n",
    "                              ToTensor(),\n",
    "                              ])\n",
    "\n",
    "train_dataset = myDataset(x, y)\n",
    "train_dataset_aug = myDataset(x, y, transform=composed)\n",
    "test_dataset = myDataset(x_test, y_test, transform=ToTensor())\n",
    "\n",
    "imshow_masked([train_dataset[i] for i in range(5)])\n",
    "\n",
    "imshow_masked([train_dataset_aug[i] for i in range(5)])\n",
    "imshow_masked([test_dataset[i] for i in range(5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset_aug, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "testloader = DataLoader(test_dataset, batch_size=4,\n",
    "                        shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=16):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "lr = 0.0001\n",
    "\n",
    "\n",
    "def log_loss_summary(loss, step, prefix=\"\"):\n",
    "    print(\"epoch {} | {}: {}\".format(step + 1, prefix + \"loss\", np.mean(loss)))\n",
    "\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = 1.0\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        y_pred = y_pred[:, 0].contiguous().view(-1)\n",
    "        y_true = y_true[:, 0].contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dsc = (2. * intersection + self.smooth) / (\n",
    "            y_pred.sum() + y_true.sum() + self.smooth\n",
    "        )\n",
    "        return 1. - dsc\n",
    "\n",
    "def IOU(preds, truth):\n",
    "    intersection = np.logical_and((preds > 0.5) == True,(truth > 0.5) == True).sum().item()\n",
    "    union = (np.logical_or((preds > 0.5),(truth > 0.5))).sum().item()\n",
    "    return intersection/union\n",
    "    \n",
    "\n",
    "imgs_log = []\n",
    "    \n",
    "unet = UNet(in_channels=3, out_channels=1)\n",
    "\n",
    "def train_validate():\n",
    "    device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda:0\")\n",
    "    \n",
    "    unet.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(unet.parameters(), lr=lr)\n",
    "    \n",
    "    loss_train_log = []\n",
    "    loss_valid_log = []\n",
    "    IOU_log = []\n",
    "    \n",
    "    loss_train = []\n",
    "    loss_valid = []\n",
    "    \n",
    "    dsc_loss = DiceLoss()\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                unet.train()\n",
    "            else:\n",
    "                unet.eval()\n",
    "    \n",
    "            validation_pred = []\n",
    "            validation_true = []\n",
    "            IOU_avg_sum = 0\n",
    "            batches = 0\n",
    "    \n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                if phase == \"train\":\n",
    "                    step += 1\n",
    "                \n",
    "                x = data['image']\n",
    "                y_true = data['mask']\n",
    "                \n",
    "                \n",
    "                \n",
    "                x, y_true = x.to(device), y_true.to(device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    y_pred = unet(x)\n",
    "                    \n",
    "                    loss = dsc_loss(y_pred, y_true)\n",
    "                    \n",
    "                    if phase == \"valid\":\n",
    "                        loss_valid.append(loss.item())\n",
    "                        y_pred_np = y_pred.detach().cpu().numpy()\n",
    "                        validation_pred.extend(\n",
    "                            [y_pred_np[s] for s in range(y_pred_np.shape[0])]\n",
    "                        )\n",
    "                        y_true_np = y_true.detach().cpu().numpy()\n",
    "                        validation_true.extend(\n",
    "                            [y_true_np[s] for s in range(y_true_np.shape[0])]\n",
    "                        )\n",
    "                        \n",
    "                        imgs_log.append((y_true_np[0],y_pred_np[0]))\n",
    "                        \n",
    "                        batch_size = y_pred_np.shape[0]\n",
    "                        IOU_batch = [IOU(y_pred_np[i],y_true_np[i]) for i in range(batch_size) ]\n",
    "                        IOU_avg_sum += sum(IOU_batch)/batch_size\n",
    "                        batches += 1\n",
    "                        \n",
    "                    if phase == \"train\":\n",
    "                        loss_train.append(loss.item())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "    \n",
    "            if phase == \"train\":\n",
    "                loss_train_log.append(np.mean(loss_train))\n",
    "                log_loss_summary(loss_train, epoch)\n",
    "                loss_train = []\n",
    "\n",
    "            if phase == \"valid\":\n",
    "                iou = IOU_avg_sum/batches\n",
    "                print(\"IOU=\", iou)\n",
    "                IOU_log.append(iou)\n",
    "                loss_valid_log.append(np.mean(loss_valid))\n",
    "                log_loss_summary(loss_valid, epoch, prefix=\"val_\")\n",
    "                loss_valid = []\n",
    "    \n",
    "    return loss_train_log,loss_valid_log, IOU_log\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda:0\")\n",
    "\n",
    "\n",
    "unet = UNet(in_channels=3, out_channels=1)\n",
    "unet.load_state_dict(torch.load('model30_noaug.mod'))\n",
    "unet.to(device)\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = []\n",
    "\n",
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda:0\")\n",
    " \n",
    "seqLoaderTrain = DataLoader(train_dataset_aug, batch_size=1,\n",
    "                        shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "dsc_loss = DiceLoss()\n",
    "    \n",
    "with torch.set_grad_enabled(False):\n",
    "    for i, data in enumerate(seqLoaderTrain, 0):\n",
    "        if i % 500 == 499 :\n",
    "            print('processed', i)\n",
    "        x = data['image']\n",
    "        y_true = data['mask']\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "        y_pred = unet(x)\n",
    "        y_pred = y_pred.cpu()\n",
    "        y_true = y_true.cpu()\n",
    "        loss = IOU(y_pred, y_true)\n",
    "        trained.append((loss, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = []\n",
    "test_dataset = myDataset(x_test, y_test, transform=composed)\n",
    "\n",
    "\n",
    "seqLoaderTest = DataLoader(test_dataset, batch_size=1,\n",
    "                        shuffle=False)\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for i, data in enumerate(seqLoaderTest, 0):\n",
    "        if i % 500 == 499 :\n",
    "            print('processed', i)\n",
    "        x = data['image']\n",
    "        y_true = data['mask']\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "        y_pred = unet(x)\n",
    "        y_pred = y_pred.cpu()\n",
    "        y_true = y_true.cpu()\n",
    "        loss = IOU(y_pred, y_true)\n",
    "        tested.append((loss, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda:0\")\n",
    "\n",
    "def show_compared(data):\n",
    "    x = data['image']\n",
    "    y_true = data['mask']\n",
    "    x, y_true = x.to(device), y_true.to(device)\n",
    "    y_pred = unet(x.reshape(1,x.shape[0], x.shape[1],x.shape[2]).double())\n",
    "    y_pred_numpy = y_pred[0].cpu().detach().permute(1,2,0).numpy()\n",
    "    \n",
    "    y_true_np = y_true.detach().cpu().permute(1,2,0).numpy()\n",
    "    \n",
    "#     intersection = np.logical_and((y_pred_numpy > 0.5) == True,(y_true_np > 0.5) == False).astype('uint8')\n",
    "    intersection = ((y_pred_numpy > 0.5) != (y_true_np > 0.5)).astype('uint8')\n",
    "    \n",
    "    pred_sample = {'image': x.detach().cpu(), 'mask':y_pred[0].detach().cpu()}\n",
    "    \n",
    "    diff = {'image': np.ones((128,128,3)).astype('uint8')*255, 'mask':intersection}\n",
    "    imshow(data['image'].permute(1,2,0))\n",
    "    imshow_masked([data,pred_sample, diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sorted = sorted(tested)\n",
    "trained_sorted[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[show_compared(train_dataset_aug[i]) for (_, i) in trained_sorted[-10:] ]\n",
    "\n",
    "time.sleep(3)\n",
    "print(\"worst\")\n",
    "\n",
    "[show_compared(train_dataset_aug[i]) for (_, i) in trained_sorted[:10] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOU(preds,trus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((preds > 0.5) ==  (trus > 0.5)).sum().item() / (128*128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(unet.state_dict(), 'model30.mod')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
